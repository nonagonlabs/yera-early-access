{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b0daad-660c-427d-b1e4-957d5c2cdca7",
   "metadata": {},
   "source": [
    "# 1 - Your First Agent: A Basic Chatbot\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this tutorial, we'll build the simplest possible Yera agent: a chatbot. This will introduce you to the core concepts of Yera's agent framework - the `@yr.agent` decorator, the event loop pattern, and Yera's built-in interaction functions.\n",
    "\n",
    "By the end, you'll understand how agents work and be ready to build more sophisticated ones.\n",
    "\n",
    "Let's start by importing Yera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "019805b3-8fc9-4acf-ad3a-7d65824de5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yera as yr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473fdbd0-37d4-461e-9a0f-f0ce9f9d7086",
   "metadata": {},
   "source": [
    "## Building a Chatbot\n",
    "\n",
    "An agent in Yera is just a Python function decorated with `@yr.agent`. This decorator tells Yera to handle the LLM orchestration, event streaming, and state management for you.\n",
    "\n",
    "Our chatbot will:\n",
    "1. Wait for user input\n",
    "2. Send it to the LLM\n",
    "3. Display the response\n",
    "4. Repeat until the user types `/quit`\n",
    "\n",
    "Here's the complete code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817ff7e8-8d1f-412c-95c1-e7b84930a6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@yr.agent\n",
    "def chatbot():\n",
    "\n",
    "    while True:\n",
    "        prompt = yr.text_input()\n",
    "\n",
    "        if prompt == \"/quit\":\n",
    "            yr.quit()\n",
    "            return\n",
    "            \n",
    "        yr.chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a370c7-4739-4ddd-957d-7bb6ca790751",
   "metadata": {},
   "source": [
    "### Understanding the Code\n",
    "\n",
    "Let's break down what's happening:\n",
    "\n",
    "**`@yr.agent`**: This decorator wraps your function to handle LLM calls, event streaming, and the conversation context. You don't need to manage API keys, message history, or parsing - Yera handles it all.\n",
    "\n",
    "**`while True:`**: Agents often run in loops, processing events continuously. This is a common pattern you'll see throughout Yera.\n",
    "\n",
    "**`yr.text_input()`**: Pauses execution and waits for user input. In a notebook, this creates an interactive input field. In production (Yera Cloud), this would wait for API calls or webhook events.\n",
    "\n",
    "**`yr.quit()`**: Signals that the agent should stop gracefully. This is important for cleanup and proper event emission.\n",
    "\n",
    "**`yr.chat(prompt)`**: Sends the prompt to the LLM and streams the response back. This maintains conversation context automatically - the LLM \"remembers\" previous messages in this session.\n",
    "\n",
    "\n",
    "## Try It Out\n",
    "\n",
    "Run the cell below and you'll see an input field appear. Try:\n",
    "- Asking questions: \"What is Python?\"\n",
    "- Multi-turn conversations: \"Tell me a joke\" followed by \"Explain why it's funny\"\n",
    "- Type `/quit` to stop the agent\n",
    "\n",
    "Notice how the LLM maintains context across your conversation - that's Yera managing the message history for you.\n",
    "\n",
    "### Understanding the Code\n",
    "\n",
    "**`chatbot()`**: Unlike normal Python functions, this starts the agent's event loop. You'll see the input field appear below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e31ea14-3f58-4481-a3ec-16a1cccec585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting \u001b[36mchatbot\u001b[0m:\n",
      "Agent: chatbot\n",
      "Module: __main__\n",
      "Identifier: __main__.chatbot\n",
      "\n",
      "Parameters (0):\n",
      "  (none)\n",
      "\n",
      "Return Type: None\n",
      "\n",
      "\n",
      "[\u001b[33mchatbot\u001b[0m]\n",
      "[\u001b[32mINPUT_REQUEST\u001b[0m]\n",
      "\n",
      "\n",
      "[\u001b[32mINPUT_ECHO\u001b[0m]\n",
      "{\n",
      "  \"content\": \"Tell me your 5 favourite words, and nothing else\"\n",
      "}\n",
      "\n",
      "[\u001b[32mMARKDOWN\u001b[0m]\n",
      "1. Serendipity\n",
      "2. Resilience\n",
      "3. Kaleidoscope\n",
      "4. Ephemeral\n",
      "5. Luminous\n",
      "[\u001b[32mINPUT_REQUEST\u001b[0m]\n",
      "\n",
      "\n",
      "\n",
      "[\u001b[36mYERA EXIT CODE 0\u001b[0m]\n",
      "{\n",
      "  \"exit_code\": 0,\n",
      "  \"reason\": \"User quit\",\n",
      "  \"return_type\": \"NoneType\",\n",
      "  \"return_value\": \"None\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dce730-4adc-4e1d-9f55-b4ca5c7cfb09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f7ce85-7c18-4b5d-989a-8b00a3691888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
